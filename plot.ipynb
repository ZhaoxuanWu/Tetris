{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from scipy.stats import sem\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_name = {'meta-llama_Llama-2-13b-hf': 'Llama-2-13B', \n",
    "              'meta-llama_Llama-2-7b-hf': 'Llama-2-7B',\n",
    "              'lmsys_vicuna-7b-v1.5': 'Vicuna-7B',\n",
    "              'lmsys_vicuna-13b-v1.5': 'Vicuna-13B',\n",
    "              'lmsys_vicuna-33b-v1.3': 'Vicuna-33B'}\n",
    "\n",
    "tp = 2\n",
    "num_runs = 3\n",
    "num_reqs = 1024\n",
    "folder = ''\n",
    "dataset = 'sharegpt'\n",
    "drafter = 'Vicuna-160M'\n",
    "bench_result_dir = \"[PATH_TO_BENCH_RESULTS]\"\n",
    "\n",
    "# for model in ['lmsys_vicuna-13b-v1.5', 'meta-llama_Llama-2-13b-hf', 'lmsys_vicuna-33b-v1.3', 'lmsys_vicuna-7b-v1.5']:\n",
    "for model in ['meta-llama_Llama-2-7b-hf', 'meta-llama_Llama-2-13b-hf']:\n",
    "    # Plotting the figure\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(5*3, 4))\n",
    "\n",
    "    plt.suptitle(f'{drafter}/{model_name[model]}: Dataset={dataset}, Tensor_Parallel={tp}', fontsize=16)\n",
    "\n",
    "    for axs_idx, max_seq_nums in enumerate([64, 128, 256]):\n",
    "        for method in ['tetris', 'baseline_sd', 'dsd']:\n",
    "            for extra_idx, extra in enumerate([1, 2, 4]):\n",
    "                # Only plot once for baseline_sd\n",
    "                if method in ['baseline_sd', 'dsd', 'no_sd'] and extra_idx > 0:\n",
    "                    continue\n",
    "\n",
    "                extra_str = f'_extra{extra}' if method == 'tetris' else ''\n",
    "                csv_file = f'{bench_result_dir}/{folder}{model}_{dataset}_{method}_tp{tp}_{num_reqs}_max{max_seq_nums}{extra_str}.csv'\n",
    "                \n",
    "                # Check if the file exists\n",
    "                if not os.path.exists(csv_file):\n",
    "                    print(f'Error: {csv_file} does not exist')\n",
    "                    continue\n",
    "\n",
    "                # Read the CSV file and remove duplicate headers\n",
    "                with open(csv_file, 'r') as file:\n",
    "                    lines = file.readlines()\n",
    "\n",
    "                # Keep the first header and remove subsequent headers\n",
    "                cleaned_lines = [lines[0]] + [line for line in lines[1:] if not line.startswith('model')]\n",
    "\n",
    "                # Convert cleaned_lines to a single string\n",
    "                cleaned_data = ''.join(cleaned_lines)\n",
    "\n",
    "                # Use StringIO to load the cleaned data into a DataFrame\n",
    "                df = pd.read_csv(StringIO(cleaned_data))\n",
    "\n",
    "                # # Display the first few rows of the dataframe\n",
    "                # print(df.head())\n",
    "\n",
    "                # Plot\n",
    "                labels = {'baseline_sd': 'Standard SD', 'tetris': 'Tetris', 'dsd': 'DSD', 'no_sd': 'w/o SD'}\n",
    "                if method == 'tetris':\n",
    "                    df['num_speculative_tokens'] = df['num_speculative_tokens'] - extra\n",
    "                extra_label = f' (extra={extra})' if method == 'tetris' else ''\n",
    "                target = 'throughput' # 'throughput', 'mean_TTFT', 'mean_TPOT', 'mean_e2el_latency'\n",
    "                if num_runs > 1:\n",
    "                    grouped = df.groupby('num_speculative_tokens').agg({target: ['mean', sem, 'count']})\n",
    "                else:\n",
    "                    grouped = df.groupby('num_speculative_tokens').agg({target: ['mean', 'count']})\n",
    "                \n",
    "                # Validate number of runs\n",
    "                if (grouped[target]['count'] != num_runs).sum() != 0:\n",
    "                    print(f'Error: {csv_file} has missing runs')\n",
    "                \n",
    "                if method == 'dsd':\n",
    "                    # Draw dotted horizontal line for DSD\n",
    "                    axs[axs_idx].axhline(y=grouped[target]['mean'].iloc[0], color='purple', linestyle='--', label=labels[method] + extra_label)\n",
    "                    if num_runs > 1:\n",
    "                        axs[axs_idx].fill_between(grouped.index, grouped[target]['mean'] - grouped[target]['sem'], grouped[target]['mean'] + grouped[target]['sem'], color='purple', alpha=0.2)\n",
    "                elif method == 'no_sd':\n",
    "                    # Draw dotted horizontal line for no sd\n",
    "                    axs[axs_idx].axhline(y=grouped[target]['mean'].iloc[0], color='black', linestyle='--', label=labels[method] + extra_label)\n",
    "                    if num_runs > 1:\n",
    "                        axs[axs_idx].fill_between(grouped.index, grouped[target]['mean'] - grouped[target]['sem'], grouped[target]['mean'] + grouped[target]['sem'], color='black', alpha=0.2)\n",
    "                else:\n",
    "                    axs[axs_idx].plot(grouped[target]['mean'], marker='o', linestyle='-', label=labels[method] + extra_label)\n",
    "                    if num_runs > 1:\n",
    "                        axs[axs_idx].fill_between(grouped.index, grouped[target]['mean'] - grouped[target]['sem'], grouped[target]['mean'] + grouped[target]['sem'], alpha=0.2)\n",
    "\n",
    "                # Add labels and title\n",
    "                axs[axs_idx].set_xlabel('No. Speculative Tokens')\n",
    "                ylabels = {'throughput': 'Mean Throughput', 'mean_TTFT': 'Mean TTFT', 'mean_TPOT': 'Mean TPOT', 'mean_e2el_latency': 'Mean End-to-end Latency'}\n",
    "                axs[axs_idx].set_ylabel(ylabels[target])\n",
    "                axs[axs_idx].set_title(f'max_seq_nums={max_seq_nums}')\n",
    "                axs[axs_idx].legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
